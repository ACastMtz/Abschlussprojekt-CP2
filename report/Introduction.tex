In the 1950's \textit{Artificial Intelligence} (AI) was born as an academic discipline and, much like a see-saw, has since then experienced fluctuations in interest and optimism about its potential as an innovative technique to expand the paradigms in the technological field. \\
As computational power increased in the late 90's and early years of the 21st century, a new found attraction for creating \textit{intelligent} machines resurrected AI. This also bringing along teeming funding; research and development became a race and AI proved itself extremely useful in several different areas, such as computer science, economics, statistics, medicine, and robotics. The algorithms that are used to teach a machine how to \textit{think} and \textit{learn} from experience in order to achieve human-level performance at carrying out specific tasks are nowadays known as \textit{Machine Learning} (ML).\\
A new era had begun: data miners started analyzing the accessible, enormous amounts of information (\textit{Big Data}) with ML algorithms, to find patterns in a quest for actionable data, thus giving birth to a broader family of ML methods, denominated \textit{Deep Learning}. One particular breakthrough of Deep Learning was the invention of \textit{Artificial Neural Networks} (ANN). \\
The main concept behind an ANN is to deploy a framework, analogous to a biological neural network, that is able to unite many distinct ML algorithms to process complex data inputs and solve a specific problem at hand. ANNs have been successful in numerous assignments, including speech and image recognition. It is the latter that this project wishes to delve itself into - its core idea being to contrive and implement a \textit{Feedforward Neural Network} on MATLAB, to recognize handwritten numbers from the MNIST database. By no means is this an original approach; it is, notwithstanding, a good introductory way of attempting to comprehend the somewhat abstruse world of deep learning and Artificial Intelligence.
